#!/usr/bin/env python3
"""
Response Composer Agent - Formata√ß√£o de Respostas Bonitas
Transforma dados t√©cnicos em respostas elegantes e amig√°veis para o usu√°rio
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, List
from openai import OpenAI

class ResponseComposerAgent:
    """
    Agente respons√°vel por compor respostas bonitas e amig√°veis
    Transforma an√°lises t√©cnicas do Python Runtime em texto humanizado
    """
    
    def __init__(self):
        """Inicializa o agente com configura√ß√µes"""
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = os.getenv("LLM_MODEL", "gpt-4o")
    
    def _build_prompt(self, state: Dict[str, Any]) -> str:
        """Constr√≥i o prompt para formata√ß√£o da resposta"""
        
        pergunta = state.get('pergunta', '')
        analysis_summary = state.get('analysis_summary', '')
        statistics = state.get('statistics', {})
        insights = state.get('insights', [])
        recommendations = state.get('recommendations', [])
        visualizations = state.get('visualizations', [])
        row_count = state.get('row_count', 0)
        
        prompt = f"""Voc√™ √© um assistente especializado em criar respostas elegantes e amig√°veis para usu√°rios de neg√≥cios.

**PERGUNTA ORIGINAL DO USU√ÅRIO:**
{pergunta}

**AN√ÅLISE T√âCNICA DISPON√çVEL:**

üìä **Resumo da An√°lise:**
{analysis_summary}

üìà **Estat√≠sticas:**
```json
{json.dumps(statistics, indent=2, ensure_ascii=False)}
```

üí° **Insights Gerados ({len(insights)}):**
```json
{json.dumps(insights, indent=2, ensure_ascii=False)}
```

üéØ **Recomenda√ß√µes ({len(recommendations)}):**
```json
{json.dumps(recommendations, indent=2, ensure_ascii=False)}
```

üìâ **Visualiza√ß√µes Sugeridas ({len(visualizations)}):**
```json
{json.dumps(visualizations, indent=2, ensure_ascii=False)}
```

**DADOS BRUTOS:**
- Total de registros: {row_count}

---

**SUA TAREFA:**

Componha uma resposta BONITA e AMIG√ÅVEL para o usu√°rio que:

1. **Responda diretamente √† pergunta** com os n√∫meros principais em destaque
2. **Use emojis apropriados** para tornar a resposta mais visual e agrad√°vel
3. **Organize as informa√ß√µes hierarquicamente** (do mais importante ao detalhe)
4. **Use formata√ß√£o Markdown** para deixar a resposta estruturada e f√°cil de ler
5. **Destaque os insights principais** que podem impactar decis√µes de neg√≥cio
6. **Apresente recomenda√ß√µes de forma acion√°vel** (o que fazer com essas informa√ß√µes)
7. **Sugira visualiza√ß√µes relevantes** se aplic√°vel
8. **Use linguagem de neg√≥cio**, evitando termos muito t√©cnicos

**ESTRUTURA RECOMENDADA:**

```markdown
## üéØ Resposta Direta
[Responda a pergunta de forma clara e direta, destacando o n√∫mero principal]

## üìä An√°lise Detalhada
[Apresente as estat√≠sticas de forma visual e organizada]

## üí° Principais Insights
[Liste os 3-5 insights mais relevantes com impacto de neg√≥cio]

## üéØ Recomenda√ß√µes
[Liste a√ß√µes pr√°ticas baseadas na an√°lise]

## üìà Visualiza√ß√µes Sugeridas
[Sugira gr√°ficos que ajudariam a entender melhor os dados]
```

**FORMATO DE RESPOSTA (JSON):**
{{
  "response_text": "Resposta completa em Markdown formatado",
  "response_summary": "Resumo de 1-2 frases da resposta",
  "key_numbers": ["n√∫mero1", "n√∫mero2", "n√∫mero3"],
  "formatting_style": "markdown_with_emojis",
  "user_friendly_score": 9.5
}}

Responda APENAS com o JSON, sem texto adicional."""
        
        return prompt
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executa composi√ß√£o da resposta formatada
        
        Args:
            state: Estado completo com an√°lise do Python Runtime
            
        Returns:
            Dict com resposta formatada
        """
        
        try:
            pergunta = state.get('pergunta', '')
            username = state.get('username', 'unknown')
            
            print(f"[RESPONSE_COMPOSER_AGENT] üé® Iniciando composi√ß√£o de resposta...")
            print(f"[RESPONSE_COMPOSER_AGENT]    Pergunta: {pergunta}")
            print(f"[RESPONSE_COMPOSER_AGENT]    Username: {username}")
            
            # Construir prompt
            prompt = self._build_prompt(state)
            
            # Chamar GPT-4o
            print(f"[RESPONSE_COMPOSER_AGENT] ü§ñ Chamando GPT-4o para formatar resposta...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em comunica√ß√£o de neg√≥cios. Crie respostas elegantes, amig√°veis e visualmente agrad√°veis. Retorne SEMPRE um JSON v√°lido."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,  # Mais criativo para respostas bonitas
                response_format={"type": "json_object"}
            )
            
            # Parsear resposta
            composed = json.loads(response.choices[0].message.content)
            
            print(f"[RESPONSE_COMPOSER_AGENT] ‚úÖ Resposta composta!")
            print(f"[RESPONSE_COMPOSER_AGENT]    Tamanho: {len(composed.get('response_text', ''))} caracteres")
            print(f"[RESPONSE_COMPOSER_AGENT]    User-friendly score: {composed.get('user_friendly_score', 0)}")
            print(f"[RESPONSE_COMPOSER_AGENT]    Tokens usados: {response.usage.total_tokens}")
            
            # Retornar resposta formatada + dados originais da an√°lise para metadata
            return {
                'response_text': composed.get('response_text', ''),
                'response_summary': composed.get('response_summary', ''),
                'key_numbers': composed.get('key_numbers', []),
                'formatting_style': composed.get('formatting_style', 'markdown_with_emojis'),
                'user_friendly_score': composed.get('user_friendly_score', 0.0),
                'tokens_used': response.usage.total_tokens,
                'model_used': self.model,
                'error': None,
                # Preservar dados da an√°lise Python Runtime para metadata
                'analysis_summary': state.get('analysis_summary', ''),
                'statistics': state.get('statistics', {}),
                'insights': state.get('insights', []),
                'visualizations': state.get('visualizations', []),
                'recommendations': state.get('recommendations', [])
            }
            
        except Exception as e:
            print(f"[RESPONSE_COMPOSER_AGENT] ‚ùå Erro na composi√ß√£o: {e}")
            return {
                'response_text': '',
                'response_summary': '',
                'key_numbers': [],
                'formatting_style': 'plain_text',
                'user_friendly_score': 0.0,
                'tokens_used': 0,
                'model_used': self.model,
                'error': str(e),
                # Preservar dados da an√°lise mesmo em caso de erro
                'analysis_summary': state.get('analysis_summary', ''),
                'statistics': state.get('statistics', {}),
                'insights': state.get('insights', []),
                'visualizations': state.get('visualizations', []),
                'recommendations': state.get('recommendations', [])
            }


if __name__ == '__main__':
    # Teste b√°sico
    agent = ResponseComposerAgent()
    
    test_state = {
        'pergunta': 'Quantas vendas tivemos ontem?',
        'username': 'test_user',
        'row_count': 1,
        'analysis_summary': 'Foram registradas 150 vendas no dia anterior.',
        'statistics': {'total': 150, 'media': 150.0},
        'insights': [
            {
                'title': 'Volume alto de vendas',
                'description': 'O volume de 150 vendas est√° acima da m√©dia di√°ria.',
                'impact': 'alto'
            }
        ],
        'recommendations': [
            {
                'action': 'Manter o estoque abastecido',
                'priority': 'alta'
            }
        ],
        'visualizations': []
    }
    
    result = agent.execute(test_state)
    print(json.dumps(result, indent=2, ensure_ascii=False))
